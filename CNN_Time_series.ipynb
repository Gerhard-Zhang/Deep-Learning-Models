{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyeemd as ped\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_fname = u'/media/hao/文件/Jupyter File/UCR_TS_Archive_2015/'\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter = ',')\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "\n",
    "def transform(x_train):\n",
    "    a = []\n",
    "    for i in range(x_train.shape[0]):\n",
    "        X_train = ped.eemd(x_train[i])\n",
    "        X_train = np.row_stack((x_train[i],X_train))\n",
    "        a.append(X_train)\n",
    "    return a\n",
    "\n",
    "fname = 'synthetic_control'\n",
    "x_train, y_train = readucr(header_fname+fname+'/'+fname+'_TRAIN')\n",
    "x_test, y_test = readucr(header_fname+fname+'/'+fname+'_TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = transform(x_train)\n",
    "X_test = transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (300, 6, 60)\n",
      "X_test.shape:  (300, 6, 60)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print('X_train.shape: ',X_train.shape)\n",
    "print('X_test.shape: ',X_test.shape)\n",
    "\n",
    "# turn into array of numpy, so that I can use in the follow-up work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 6 60\n",
      "300 6 60\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0],X_train.shape[1], X_train.shape[2])\n",
    "print(X_test.shape[0],X_test.shape[1],X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 全局变量\n",
    "batch_size = 128\n",
    "nb_classes = len(np.unique(y_test))\n",
    "epochs = 200\n",
    "# input image dimensions\n",
    "img_rows, img_cols = X_train.shape[1], X_train.shape[2]\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -3.76940000e-01,   1.22490000e+00,   3.43870000e-01, ...,\n",
       "           9.18350000e-01,  -1.31170000e+00,  -1.19710000e+00],\n",
       "        [ -4.42260053e-01,   3.69372682e-01,  -3.19439096e-01, ...,\n",
       "           5.23777444e-01,  -5.25900592e-01,   4.46585949e-01],\n",
       "        [ -3.82021023e-01,   3.29412584e-01,   2.01652294e-01, ...,\n",
       "           4.54724682e-01,  -6.41720500e-01,  -1.40217778e+00],\n",
       "        [  1.04766288e-01,   1.46498223e-01,   7.38122649e-02, ...,\n",
       "          -8.35486141e-03,  -4.18466952e-02,  -1.39482849e-01],\n",
       "        [ -1.95607961e-01,  -1.29142270e-01,  -6.51052955e-02, ...,\n",
       "          -7.27095980e-02,  -1.14592727e-01,  -1.57457788e-01],\n",
       "        [  5.39125284e-01,   5.06330310e-01,   4.73741415e-01, ...,\n",
       "           2.34504733e-02,   3.53327104e-02,   4.71159426e-02]],\n",
       "\n",
       "       [[  6.44410000e-01,   4.13270000e-01,  -8.62280000e-01, ...,\n",
       "           1.39810000e+00,   8.57420000e-02,   2.49970000e-02],\n",
       "        [ -1.69332970e-01,   3.76683405e-01,  -2.37503339e-01, ...,\n",
       "           8.17598591e-01,  -4.67873069e-01,  -3.25210821e-01],\n",
       "        [ -4.12952015e-04,  -3.48504976e-02,  -2.26948699e-01, ...,\n",
       "           2.40072982e-01,   1.31254361e-01,  -2.14097659e-01],\n",
       "        [  6.45008404e-01,   1.01918730e-01,  -1.87656358e-01, ...,\n",
       "          -3.27196293e-01,  -2.02070063e-01,  -5.92022831e-02],\n",
       "        [  1.76670585e-01,  -2.14222160e-02,  -1.73231870e-01, ...,\n",
       "           3.36974321e-01,   2.98832944e-01,   2.51245700e-01],\n",
       "        [ -6.58053341e-03,  -1.14878898e-02,  -1.61481816e-02, ...,\n",
       "           3.33188535e-01,   3.48569990e-01,   3.63945548e-01]],\n",
       "\n",
       "       [[ -9.78670000e-01,  -4.06230000e-01,   8.22430000e-01, ...,\n",
       "           6.66130000e-01,   1.07000000e-01,   8.27150000e-02],\n",
       "        [  8.68712618e-03,   4.80794298e-01,   1.53948462e+00, ...,\n",
       "           2.57309878e-01,  -1.18717436e-01,  -1.78670353e-03],\n",
       "        [ -1.97348066e-01,  -2.73997364e-01,  -2.19507445e-01, ...,\n",
       "           6.10552063e-02,   1.84324969e-02,   1.80044565e-02],\n",
       "        [ -1.40684004e-01,  -4.64031149e-02,   2.18735056e-02, ...,\n",
       "           3.11678042e-01,   1.98317095e-01,   3.60398425e-02],\n",
       "        [ -1.22669716e-01,  -7.36612310e-02,  -3.22188707e-02, ...,\n",
       "          -6.99428486e-03,  -1.62209418e-02,  -2.85717549e-02],\n",
       "        [ -5.25712809e-01,  -4.95391049e-01,  -4.66410322e-01, ...,\n",
       "           4.56192856e-02,   4.81608734e-02,   5.07126724e-02]],\n",
       "\n",
       "       ..., \n",
       "       [[  9.65900000e-01,   6.40160000e-01,   4.80860000e-01, ...,\n",
       "          -6.83360000e-01,  -1.19570000e+00,  -8.03640000e-01],\n",
       "        [  1.83053303e-01,  -3.10091146e-04,  -7.87495518e-02, ...,\n",
       "           4.12307982e-01,  -1.90748222e-01,  -5.92406401e-02],\n",
       "        [  9.18644615e-02,   2.29036639e-03,  -2.91823849e-02, ...,\n",
       "          -1.79865049e-01,  -1.43529722e-01,   2.42527059e-02],\n",
       "        [ -3.68215273e-02,  -8.02074228e-02,  -9.97873185e-02, ...,\n",
       "           9.08098764e-02,   1.08868250e-01,   1.10442818e-01],\n",
       "        [ -6.72136648e-02,  -7.87735251e-02,  -8.25263803e-02, ...,\n",
       "           2.66297274e-01,   3.81776490e-01,   5.00624163e-01],\n",
       "        [  7.95959961e-01,   7.94732208e-01,   7.91897160e-01, ...,\n",
       "          -1.27037195e+00,  -1.32909466e+00,  -1.38803555e+00]],\n",
       "\n",
       "       [[  3.54970000e-01,   1.09650000e-01,   2.38900000e-01, ...,\n",
       "          -1.62540000e+00,  -1.76540000e+00,  -1.67540000e+00],\n",
       "        [ -8.87103571e-02,  -3.21643846e-01,  -1.76998791e-01, ...,\n",
       "          -4.00979952e-01,  -3.28348805e-01,  -1.36796931e-01],\n",
       "        [  2.58361154e-03,  -6.91986606e-02,  -1.13429757e-01, ...,\n",
       "           1.13148527e-01,  -1.52473455e-02,  -9.11568878e-02],\n",
       "        [ -1.51573738e-01,  -1.07798769e-01,  -6.61858172e-02, ...,\n",
       "           7.34004444e-01,   6.53987259e-01,   5.66683928e-01],\n",
       "        [  8.53160656e-02,   5.88763178e-02,   3.39928875e-02, ...,\n",
       "           8.35898942e-03,   1.34049657e-01,   2.74962234e-01],\n",
       "        [  5.08296951e-01,   5.46986494e-01,   5.82312989e-01, ...,\n",
       "          -2.07739388e+00,  -2.18686865e+00,  -2.29740884e+00]],\n",
       "\n",
       "       [[  6.46620000e-01,   6.13520000e-01,   1.12670000e+00, ...,\n",
       "          -2.39570000e-02,  -8.33350000e-01,  -2.61180000e-01],\n",
       "        [ -7.56129640e-02,  -1.98247645e-01,   2.61609198e-01, ...,\n",
       "           5.67062615e-01,  -5.69096570e-01,  -2.46239272e-01],\n",
       "        [ -8.81646616e-02,  -2.23045871e-01,  -3.27998619e-01, ...,\n",
       "           9.56800952e-02,   2.88700769e-01,   2.79286014e-01],\n",
       "        [ -1.48791954e-01,  -2.97910511e-02,   6.23847735e-02, ...,\n",
       "          -9.72802135e-02,   4.56096988e-02,   2.58653994e-01],\n",
       "        [ -4.75749948e-01,  -3.12158561e-01,  -1.61489329e-01, ...,\n",
       "          -3.08484749e-02,  -3.32740937e-02,  -3.49599844e-02],\n",
       "        [  1.43588206e+00,   1.37433466e+00,   1.31298556e+00, ...,\n",
       "          -5.56032882e-01,  -5.42317607e-01,  -5.26237278e-01]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "'''\n",
    "array([[[0, 0, 0, ..., 0, 0, 0],\n",
    "        [0, 0, 0, ..., 0, 0, 0],\n",
    "        ..., \n",
    "        [0, 0, 0, ..., 0, 0, 0]],\n",
    "       ...,\n",
    "       [[0, 0, 0, ..., 0, 0, 0],\n",
    "        [0, 0, 0, ..., 0, 0, 0], \n",
    "        ..., \n",
    "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)\n",
    "'''\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape  # output (300, 6, 60)\n",
    "X_test.shape   # output (300, 6, 60)\n",
    "y_test.shape   # output (300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据不同的backend定下不同的格式\n",
    "if K.image_dim_ordering() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (300, 6, 60, 1)\n",
      "300 train samples\n",
      "300 test samples\n"
     ]
    }
   ],
   "source": [
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  3.,  3.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
       "        5.,  5.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 转换为one_hot类型\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# here comes a problem that the number are begin from 1 to 6, not 0 to 5\n",
    "# so I need to add 1 in nb_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 300 samples\n",
      "Epoch 1/200\n",
      "300/300 [==============================] - 0s - loss: 1.7703 - acc: 0.2233 - val_loss: 1.6558 - val_acc: 0.6767\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s - loss: 1.6268 - acc: 0.4300 - val_loss: 1.4905 - val_acc: 0.6800\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s - loss: 1.4695 - acc: 0.6067 - val_loss: 1.2877 - val_acc: 0.7467\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s - loss: 1.2676 - acc: 0.6300 - val_loss: 1.0808 - val_acc: 0.6833\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s - loss: 1.0386 - acc: 0.6967 - val_loss: 0.8483 - val_acc: 0.8167\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s - loss: 0.8242 - acc: 0.7700 - val_loss: 0.6777 - val_acc: 0.8000\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s - loss: 0.7170 - acc: 0.7800 - val_loss: 0.5313 - val_acc: 0.9133\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s - loss: 0.6244 - acc: 0.7967 - val_loss: 0.4548 - val_acc: 0.9200\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s - loss: 0.4832 - acc: 0.8500 - val_loss: 0.4498 - val_acc: 0.8333\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s - loss: 0.4447 - acc: 0.8367 - val_loss: 0.3139 - val_acc: 0.9567\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s - loss: 0.3593 - acc: 0.8867 - val_loss: 0.3570 - val_acc: 0.8833\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s - loss: 0.4001 - acc: 0.8533 - val_loss: 0.2845 - val_acc: 0.9300\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s - loss: 0.2836 - acc: 0.9233 - val_loss: 0.2203 - val_acc: 0.9700\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s - loss: 0.2597 - acc: 0.9267 - val_loss: 0.2011 - val_acc: 0.9467\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s - loss: 0.2119 - acc: 0.9400 - val_loss: 0.1638 - val_acc: 0.9667\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s - loss: 0.1955 - acc: 0.9567 - val_loss: 0.1623 - val_acc: 0.9667\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s - loss: 0.1759 - acc: 0.9633 - val_loss: 0.1643 - val_acc: 0.9533\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s - loss: 0.1559 - acc: 0.9667 - val_loss: 0.1734 - val_acc: 0.9400\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s - loss: 0.1653 - acc: 0.9400 - val_loss: 0.1114 - val_acc: 0.9833\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s - loss: 0.1474 - acc: 0.9633 - val_loss: 0.1137 - val_acc: 0.9867\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s - loss: 0.1413 - acc: 0.9667 - val_loss: 0.0930 - val_acc: 0.9867\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s - loss: 0.1127 - acc: 0.9800 - val_loss: 0.1312 - val_acc: 0.9633\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s - loss: 0.1091 - acc: 0.9733 - val_loss: 0.1095 - val_acc: 0.9900\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s - loss: 0.0971 - acc: 0.9833 - val_loss: 0.0851 - val_acc: 0.9833\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s - loss: 0.0868 - acc: 0.9800 - val_loss: 0.0706 - val_acc: 0.9867\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s - loss: 0.1019 - acc: 0.9700 - val_loss: 0.0660 - val_acc: 0.9867\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s - loss: 0.0758 - acc: 0.9867 - val_loss: 0.0632 - val_acc: 0.9867\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s - loss: 0.0843 - acc: 0.9833 - val_loss: 0.0591 - val_acc: 0.9867\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s - loss: 0.0498 - acc: 0.9933 - val_loss: 0.0578 - val_acc: 0.9867\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s - loss: 0.0644 - acc: 0.9900 - val_loss: 0.0737 - val_acc: 0.9867\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s - loss: 0.0938 - acc: 0.9767 - val_loss: 0.0732 - val_acc: 0.9867\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s - loss: 0.0661 - acc: 0.9800 - val_loss: 0.0495 - val_acc: 0.9867\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s - loss: 0.0473 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 0.9867\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s - loss: 0.0521 - acc: 0.9933 - val_loss: 0.0515 - val_acc: 0.9900\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s - loss: 0.0530 - acc: 0.9933 - val_loss: 0.0442 - val_acc: 0.9933\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s - loss: 0.0468 - acc: 0.9933 - val_loss: 0.0460 - val_acc: 0.9933\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s - loss: 0.0630 - acc: 0.9833 - val_loss: 0.0437 - val_acc: 0.9867\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s - loss: 0.0505 - acc: 0.9900 - val_loss: 0.0394 - val_acc: 0.9933\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s - loss: 0.0468 - acc: 0.9933 - val_loss: 0.0472 - val_acc: 0.9900\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s - loss: 0.0521 - acc: 0.9833 - val_loss: 0.0541 - val_acc: 0.9867\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s - loss: 0.0502 - acc: 0.9833 - val_loss: 0.0365 - val_acc: 0.9900\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s - loss: 0.0299 - acc: 0.9967 - val_loss: 0.0362 - val_acc: 0.9867\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s - loss: 0.0282 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 0.9900\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s - loss: 0.0306 - acc: 0.9933 - val_loss: 0.0437 - val_acc: 0.9933\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s - loss: 0.0349 - acc: 0.9933 - val_loss: 0.0341 - val_acc: 0.9867\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s - loss: 0.0303 - acc: 0.9933 - val_loss: 0.0367 - val_acc: 0.9867\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s - loss: 0.0571 - acc: 0.9900 - val_loss: 0.0331 - val_acc: 0.9933\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s - loss: 0.0579 - acc: 0.9833 - val_loss: 0.0381 - val_acc: 0.9933\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s - loss: 0.0304 - acc: 0.9967 - val_loss: 0.0318 - val_acc: 0.9900\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s - loss: 0.0289 - acc: 0.9967 - val_loss: 0.0290 - val_acc: 0.9900\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s - loss: 0.0328 - acc: 0.9933 - val_loss: 0.0291 - val_acc: 0.9933\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s - loss: 0.0288 - acc: 0.9933 - val_loss: 0.0298 - val_acc: 0.9933\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s - loss: 0.0221 - acc: 0.9967 - val_loss: 0.0274 - val_acc: 0.9867\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s - loss: 0.0271 - acc: 0.9967 - val_loss: 0.0316 - val_acc: 0.9933\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 0.9900\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s - loss: 0.0245 - acc: 0.9933 - val_loss: 0.0283 - val_acc: 0.9933\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s - loss: 0.0297 - acc: 0.9933 - val_loss: 0.0239 - val_acc: 0.9933\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s - loss: 0.0297 - acc: 0.9933 - val_loss: 0.0253 - val_acc: 0.9967\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s - loss: 0.0191 - acc: 0.9967 - val_loss: 0.0232 - val_acc: 0.9933\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s - loss: 0.0237 - acc: 0.9967 - val_loss: 0.0227 - val_acc: 0.9933\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s - loss: 0.0232 - acc: 0.9967 - val_loss: 0.0244 - val_acc: 0.9933\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9867\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9933\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s - loss: 0.0177 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9933\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s - loss: 0.0231 - acc: 0.9900 - val_loss: 0.0221 - val_acc: 0.9933\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s - loss: 0.0183 - acc: 0.9967 - val_loss: 0.0220 - val_acc: 0.9933\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s - loss: 0.0218 - acc: 0.9933 - val_loss: 0.0211 - val_acc: 0.9900\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s - loss: 0.0222 - acc: 0.9967 - val_loss: 0.0215 - val_acc: 0.9867\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s - loss: 0.0234 - acc: 0.9967 - val_loss: 0.0206 - val_acc: 0.9867\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s - loss: 0.0260 - acc: 0.9900 - val_loss: 0.0207 - val_acc: 0.9933\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9933\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s - loss: 0.0180 - acc: 0.9967 - val_loss: 0.0220 - val_acc: 0.9900\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s - loss: 0.0324 - acc: 0.9867 - val_loss: 0.0202 - val_acc: 0.9900\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 0.9933\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 0.9867\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9933\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s - loss: 0.0133 - acc: 0.9967 - val_loss: 0.0208 - val_acc: 0.9900\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 0.9933\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s - loss: 0.0190 - acc: 0.9967 - val_loss: 0.0184 - val_acc: 0.9967\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 0.9933\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9900\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s - loss: 0.0180 - acc: 0.9967 - val_loss: 0.0197 - val_acc: 0.9900\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s - loss: 0.0147 - acc: 0.9967 - val_loss: 0.0185 - val_acc: 0.9933\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 0.9933\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s - loss: 0.0158 - acc: 0.9967 - val_loss: 0.0170 - val_acc: 0.9933\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0200 - val_acc: 0.9933\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9933\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0164 - val_acc: 0.9933\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s - loss: 0.0171 - acc: 0.9967 - val_loss: 0.0174 - val_acc: 0.9933\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s - loss: 0.0120 - acc: 0.9967 - val_loss: 0.0172 - val_acc: 0.9933\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9933\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0161 - val_acc: 0.9933\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.0160 - val_acc: 0.9933\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0189 - val_acc: 0.9933\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s - loss: 0.0119 - acc: 0.9967 - val_loss: 0.0161 - val_acc: 0.9933\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s - loss: 0.0082 - acc: 0.9967 - val_loss: 0.0178 - val_acc: 0.9933\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 0.9933\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 0.9933\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0149 - val_acc: 0.9933\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s - loss: 0.0134 - acc: 0.9933 - val_loss: 0.0170 - val_acc: 0.9933\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 0.9933\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s - loss: 0.0202 - acc: 0.9900 - val_loss: 0.0171 - val_acc: 0.9933\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s - loss: 0.0134 - acc: 0.9933 - val_loss: 0.0161 - val_acc: 0.9933\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9933\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0191 - val_acc: 0.9933\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9933\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9933\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9933\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9933\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 0.9933\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0234 - val_acc: 0.9900\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9900\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 0.9933\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9933\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9933\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 0.9933\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9967\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9933\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s - loss: 0.0067 - acc: 0.9967 - val_loss: 0.0126 - val_acc: 0.9933\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9933\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s - loss: 0.0064 - acc: 0.9967 - val_loss: 0.0159 - val_acc: 0.9933\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s - loss: 0.0084 - acc: 0.9967 - val_loss: 0.0124 - val_acc: 0.9967\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9967\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 0.9933\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9933\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 0.9933\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9933\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9933\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9933\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 0.9933\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9933\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9967\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 0.9933\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9933\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9933\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9933\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s - loss: 0.0083 - acc: 0.9967 - val_loss: 0.0129 - val_acc: 0.9933\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 0.9933\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0118 - val_acc: 0.9933\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9967\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0116 - val_acc: 0.9967\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s - loss: 0.0055 - acc: 0.9967 - val_loss: 0.0105 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s - loss: 0.0121 - acc: 0.9933 - val_loss: 0.0104 - val_acc: 0.9967\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s - loss: 0.0069 - acc: 0.9967 - val_loss: 0.0109 - val_acc: 0.9967\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9967\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9933\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9933\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9967\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s - loss: 0.0082 - acc: 0.9933 - val_loss: 0.0116 - val_acc: 0.9933\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9933\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 0.9933\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9933\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0144 - val_acc: 0.9933\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9967\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9933\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9967\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9933\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s - loss: 0.0051 - acc: 0.9967 - val_loss: 0.0103 - val_acc: 0.9933\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9967\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9933\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9967\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9933\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9933\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9933\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9933\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9967\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s - loss: 0.0081 - acc: 0.9967 - val_loss: 0.0143 - val_acc: 0.9933\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s - loss: 9.5560e-04 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9933\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9933\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9967\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9967\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 0.9967\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9967\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s - loss: 0.0074 - acc: 0.9967 - val_loss: 0.0132 - val_acc: 0.9933\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9967\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9933\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9933\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9933\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s - loss: 0.0050 - acc: 0.9967 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s - loss: 0.0078 - acc: 0.9933 - val_loss: 0.0076 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s - loss: 0.0046 - acc: 0.9967 - val_loss: 0.0100 - val_acc: 0.9933\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9933\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9933\n",
      "Test score: 0.00919696692998\n",
      "Test accuracy: 0.993333333333\n"
     ]
    }
   ],
   "source": [
    "#构建模型\n",
    "model = Sequential()\n",
    "\"\"\"\n",
    "model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='same',\n",
    "                        input_shape=input_shape))\n",
    "\"\"\"\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "                        padding='same',\n",
    "                        input_shape=input_shape)) # 卷积层1\n",
    "model.add(Activation('relu')) #激活层\n",
    "model.add(Convolution2D(nb_filters, (kernel_size[0], kernel_size[1]))) #卷积层2\n",
    "model.add(Activation('relu')) #激活层\n",
    "model.add(MaxPooling2D(pool_size=pool_size)) #池化层\n",
    "model.add(Dropout(0.25)) #神经元随机失活\n",
    "model.add(Flatten()) #拉成一维数据\n",
    "model.add(Dense(128)) #全连接层1\n",
    "model.add(Activation('relu')) #激活层\n",
    "model.add(Dropout(0.5)) #随机失活\n",
    "model.add(Dense(nb_classes)) #全连接层2\n",
    "model.add(Activation('softmax')) #Softmax评分\n",
    "\n",
    "#编译模型\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "#训练模型\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "#评估模型\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
